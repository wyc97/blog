---
title: MySQL
date: '2024-06-19T06:27:36.000Z'
excerpt: "## 存储引擎 mysql 开源的支持多种存储引擎，常见的是 InnoDB、MyISAM。 区别： \t- InnoDB 支持事务，MyISAM 不支持 \t- InnoDB 是聚集索引，MyISAM 非..."
tags:
  - Imported
category: Notes
---
## 存储引擎
mysql 开源的支持多种存储引擎，常见的是 InnoDB、MyISAM。
区别：
	- InnoDB 支持事务，MyISAM 不支持
	- InnoDB 是聚集索引，MyISAM 非聚集索引，索引和数据分离的存储方式
	- InnoDB 支持外键，MyISAM 不支持
	- InnoDB 最小锁粒度是行锁，MyISAM 是表锁
	- 清空表时 InnoDB 一行一行的删除，MyISAM 重建表。
## 数据库范式
1. 数据库表的属性是原子性
2. 数据库表中的每个实例或记录必须可以被唯一的区分（要有主键）
3. 任何非主属性不能依赖于其他非主属性（主键外的字段不能相互依赖）
如果建表的时候满足 3 范式的话，可以避免一些数据的写入异常，提高写入性能，同样的会丢失读取性能。但实际上遇到多表查询的时候，遵守 3 范式会导师查询效率变低（因为表中不能存在冗余字段）。要知道 join 查询的时候效率是很慢的，适当添加一些冗余字段能够避免多表关联查询。
## 多表查询
mysql 的多表查询都是基于嵌套查询的，简单来说就是一张表作为外循环，另一张作内循环，外循环的每一条记录都需要和内循环的作比较，符合条件的输出。
尽管 mysql 的优化器会在具体执行的时候最小代价来将一张表作为驱动表。
嵌套算法：
- simple nested loop: 全量扫描，两两数据进行对比。
- block nested loop：引入 buffer，提前把外循环的一部分数据放入 join buffer 中，因为是在内存所以效率会高一点，但复杂度还是 n*m
- index nested loop：如果存在索引的话，会通过索引查询数据，mysql 的索引是基于 B+树的，所以复杂度近似于 n*logm

mysql 在 8.0 后引入了 hash join。实际上就是把驱动表的数据构建进 hash 表中。当在非驱动表中查询一条记录的时候，会去hash 中查匹配记录。

**驱动表选取规则：**
- 表大小：小表作为驱动表可以更快地被扫描和匹配，所以优化器倾向小表
- 索引： 索引能极大影响查询效率，所以选择有索引的表作为驱动表更有效率。
- where 条件： 如果查询有 where 条件，那么选择能够使用过滤条件筛选的表作为驱动表减少后续的匹配操作。
- 连接类型：left join-选择左表、right join-选择右表、inner join-选择数据量小的表，这些都不是一定的还是要根据前面 3 个规则来。
- 可以使用 STRAIGHT_JOIN 来强制指定表的连接顺序（只适用于内连接）select * from t1 STRAIGHT_JOIN t2 on t1.id=t2.id
## 索引
### 索引结构
- 主键是聚簇索引：非叶子节点存储的是索引的值，叶子节点存储的是整条数据
- 普通索引是非聚簇索引：数据和索引分开存储，叶子节点存储的索引的值以及主键的值
通过非聚簇索引的查询需要经过一次回表。

**如何减少回表？**
- 尽量使用聚簇索引
- 覆盖索引
- 索引下推 5.6 版本后默认优化策略（在索引失效的情况下优化手段）
### SQL 调优
SQL 慢有可能是以下原因
1. 索引失效
2. 多表 join
3. 查询字段太多
4. 数据量大（分库分表）
5. 索引区分度不高
6. 数据库连接数不够
7. 表结构不合理
8. 数据库 I/O 或者 CPU 高
9. 数据库参数不合理
10. 事务比较长
11. 锁竞争导致的等待
首先关注 1，索引失效有很多原因主要是先看执行计划。
#### 执行计划
通过 explain 来查看 sql 语句的执行计划，从而提升 SQL 查询语句的性能。

| 字段名               | 用途                                     |
| ----------------- | -------------------------------------- |
| id                | 每个 select 关键字都对应一个 id                  |
| select_type       | select 关键字对应的查询类型                      |
| table             | 表名                                     |
| partitions        | 匹配的分区信息                                |
| **type**          | 查询时所用到的索引类型 ALL、index、range、ref、eq_ref |
| **possible_keys** | 可能被优化器选择使用的索引                          |
| **key**           | 查询优化器实际使用的索引                           |
| key_len           | 实际使用到的索引长度                             |
| ref               | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息            |
| rows              | 预计需要读取的记录条数                            |
| filtered          | 某个表经过条件过滤后剩余的记录条数百分比                   |
| **Extra**         | 一些额外的信息                                |
|                   |                                        |
|                   |                                        |
![](/images/posts/mysql/Pasted-image-20240620163536.png)
具体查询效率排序：system>const>eq_ref>ref>range>index>all

所以应该先看执行计划是否用到了索引。
> key 一定要有值，不能是 null
> type 应该是 ref、eq_ref、range、const 等这几个
> extra 如果是 null、using index、using index condition 都可以

如果以下几种情况可能导致没有走索引：
- 没有正确的创建索引或者不符合最左匹配原则
- 索引区分度不高比如性别。
- 表太小
- 查询语句中索引字段使用了函数、索引值类型不匹配
- 使用了 or 并且两边存在`</>` 导致索引失效。
- like 操作不符合最左  like='%ddddd%'
- 不等于比较有可能也会导致
- is not null 
- in  如果 in 中的值比较少的时候会走索引优化如果值比较多的话可能会导致索引失效。
**连接数不够**：要看具体分析如果是业务量太大就只能分库，如果是存在一些慢 SQL 或者长事务一直占着链接数，那么就需要具体分析解决

**参数设置不合理**：重点看几个参数 show variables like 'innodb%'
1. innodb_buffer_pool_size: 缓冲区大小，一般设置为服务器内存的 70%-80%。（set global innodb_buffer_pool_size=6G;）
2. innodb_read_io_threads 和 innodb_writes_io_threads 这两个参数控制着 innodb 存储引擎使用的 I/O 进程数通常情况下设置为 CPU 核心数的一半。（set global innodb_read_io_threads=4;）
3. innodb_log_file: 这个参数控制事务日志文件的大小，默认是 5M 远远不够，一般设置为 1 G 或者内存的 1/4。（set global innodb_log_file=1G;）



## 执行过程
![](/images/posts/mysql/Pasted-image-20240619150644.png)

## 行格式
数据库的行格式决定了数据是如何进行物理存储，进而影响查询和 DML 操作性能。
常见有 4 种
1. COMPACT：5.0 之前的默认格式，除了保存值之外，还会记录变长字段长度列和记录头信息，利用空值列表保存 null 值。适合处理大量包含可变长度列（varchar、blob、text）
	![](/images/posts/mysql/Pasted-image-20240619151322.png)
2. DYNAMIC：5.7 引入，是 compact 格式改进版，保存了 compact 格式的优点，同时在存储可变长度列表时更加灵活，能够动态选择存储在页外还是页内。
## 数据库事务
1. 原子性：事务作为一个整体被执行，在其中的操作要么全部被执行，要么全部不执行。
2. 一致性：事务应该确保数据库的状态从一个一致状态变成另一个一致状态。一致状态的含义是指数据库中的数据应满足完整性约束。
3. 隔离性：多个事务并发执行时彼此不会相互影响。
4. 持久性：事务一旦提交，他对数据的修改应该永久保存在数据库中。


- 脏读：读取到了其他事务还没有提交的数据
- 不可重复读：两个读取数据的过程中，有其他事务对该数据进行修改导致两次读取的结果不同。
- 幻读：事务在范围查询的过程中，有另一个事务对数据进行了修改，导致范围查询的结果记录不一致。
事务有 4 中隔离级别来解决脏读、不可重复读、幻读的问题
1. 未提交读：一个事务可以读取到另一个事务未提交的数据。
2. 提交读：在一个事务修改数据但还没有提交的时候，其他事务不能读取该数据。
3. 可重复读：保证同一个事务在多次读取的同样的记录结果是一致的。（**该隔离级别下解决不可重复读是因为同一事务中每次快照读取的都是同一版本数据，即使别的事务修改了该数据，读取的还是上一次的历史数据版本，所以才不会出现不可重复读的现象**）
4. 可串行化：所有的操作都会加上锁。
## 主从复制
通过搭建 mysql 集群，整体对外提供服务。集群分为主服务器和从服务器，主服务器提供写服务，从服务器提供读服务。
为了保证主从服务器数据的一致性，需要进行数据同步，过程如下：
![](/images/posts/mysql/Pasted-image-20240620145532.png)
mysql 在进行主从复制的时候数据的同步是通过 binlog 来进行的。
1. 从服务器在开启主从复制的时候会创建两个线程 I/O 和 SQL 线程。
2. 从服务器的 I/O 线程会尝试和主服务器建立连接，相应的主服务器会有个 Dump 线程专门用来和从服务器的 I/O 线程同步
3. **从服务器的 I/O 线程会主动告诉主服务器从哪里开始同步**
4. 主服务器数据变更的时候会将记录写入到 binlog 中，dump 线程检测到 binlog 发生改变后会从指定位置开始读取。接着从服务器的 I/O 线程会拉取
5. 从服务器 I/O 线程拉取到的内容会保存在 relay log 中。
6. SQL 读取 relay log 中的内容解析成具体操作然后写入到数据库表中。

那么 binlog 的数据格式有哪些？statement、row、mixed。RR 隔离级别下支持这三种数据格式，RC 隔离级别仅支持 row 数据格式。

- statement：存储的是 sql 原文。
- Row：格式的 binlog 记录的是每行数据的变化。当 MySQL 执行一个 SQL 语句时，它会将这个 SQL 语句影响的每一行数据的变化都记录到 binlog 中。
- Mixed：格式的 binlog 是 statement 和 row 两种格式的混合。MySQL 会根据 SQL 语句的类型和内容，动态地选择使用 statement 格式还是 row 格式。

如果想要提高并发可以修改事物的隔离级别为 RC。因为他在修改的时候不会加上 gaplock 和 next-key lock。但是需要自己解决不可重复读的问题，但其实不可重复读问题不大，即使读取到了别的事务提交的数据，可以通过添加乐观锁字段，并且在修改的时候带上乐观锁标记值即可。

## MySQL 锁
具体看这
https://blog.csdn.net/qq_38238296/article/details/88362999

**关于幻读问题：**
首先理解快照读和当前读：
- 快照读：读取快照的数据，通常普通的 select 语句就是快照读。
- 当前读：就是读加锁. select ** for update/select ** lock in share mode/inset/update/delete 语句都会当前读。
在 RC 级别下每次读取都是最新的快照，所以无法解决不可重复读的问题。在 RR 级别下快照会在事务的第一次 select 语句中生成，只有在本事务中更新数据的时候才会更新快照。因此一个事务的多次查询是不会查询到其他事务中变更的内容，因此可以解决幻读的问题。但是不能处理所有情况。

因此对于快照读和当前读是能够处理幻读的问题，但是如果一个事务不仅进行了快照读也进行了当前读那么可能存在幻读的问题。
如下所示：
![](/images/posts/mysql/Pasted-image-20240619185319.png)
想要彻底解决幻读问题只能使用 Serialized 这种隔离级别，读写都加锁。

## MYSQL 和 PG 的区别
**数据类型：** MySQL支持BINARY和VARBINARY类型，用于存储二进制字符串。PostgreSQL则提供了BYTEA类型，用于存储二进制数据。
postgreSQL支持一些MySQL不支持的特殊类型，如ARRAY（用于存储数组），HSTORE（用于存储键值对），JSON（用于存储JSON数据），和UUID（用于存储通用唯一标识符）等

**索引：**
1. **索引类型**：MySQL支持B-Tree, Hash, R-Tree, 和 Full-text索引类型。PostgreSQL支持更多的索引类型，包括B-Tree, Hash, GiST, SP-GiST, GIN, 和 BRIN。其中，GiST和SP-GiST索引可以用于多种数据类型，包括范围查询和多维数据查询，GIN索引适用于包含多个组件的数据类型，如数组和全文搜索，BRIN索引适用于非常大的表，它根据数据的相似性将数据分组。
2. **索引方法**：MySQL支持单列索引和复合索引，但不支持表达式索引。PostgreSQL不仅支持单列索引和复合索引，还支持表达式索引，这意味着你可以在索引中使用表达式或函数。
3. **空间索引**：MySQL支持空间索引，主要用于地理空间数据的查询。PostgreSQL也支持空间索引，但它使用的是PostGIS扩展，这是一个强大的地理信息系统，提供了更多的空间数据类型和函数


## 分库分表
首先分库分表是 3 种。分库、分表、分库分表。
如果要是解决并发的问题那么可以用分库，如果是要解决数据量大的问题可以用分表，同时就用分库分表。
**分库分表工具**
Sharding-JDBC、TDDL、MyCat

**分表算法**
- 直接取模
- 关键字
- hash 取模：如果分表类型是字符类型，那么可以用先 hash 然后在取模，但是需要注意取模得到负数的情况
- 一致性 hash：如果后续需要扩容，那么如果之前用的是 hash 取模的算法，那么扩容后有需要重新 hash 就会有数据迁移的问题。一致性哈希算法首先构造一个环状结构，将表和数据都映射到这个环上面（通过 hash），然后分表的时候，数据顺时针在环上找第一个表的节点，存储在这个表里面。如果表需要扩容，那么发生数据迁移的也只会影响一部分数据（只有增加表的位置和逆时针第一个表之间的键会受影响）。
**分布式 id**
1. uuid：首先就是 uuid 是字符串，如果数据量大那么查询效率不是很高
2. 基于单表做自增 id：由于多表的自增 id 肯定会冲突，那么可以让所有的表都从一个表中获取自增 id，那么就不会有重复问题。缺点就是这个表是整个数据库的性能瓶颈，而且也存在单点的问题。
3. 多个表+步长做自增：和上面的一样只不过是多个表，每个表的起始数不一样并且给每个表设置步长。
4. 雪花算法：常用的分布式 id，全局唯一、递增、高可用。有 4 部分组成 1bit 符号位、41bit 时间戳位、10bit 工作进程位、12bit 序列号位。
